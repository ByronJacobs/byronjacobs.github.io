<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 Ordinary Differentiable Equations (ODEs) | Numerical Analysis B</title>
  <meta name="description" content="These are the course notes for the numerical methods honours course taught to applied mathematics students at University of Johannesburg" />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 Ordinary Differentiable Equations (ODEs) | Numerical Analysis B" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="These are the course notes for the numerical methods honours course taught to applied mathematics students at University of Johannesburg" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Ordinary Differentiable Equations (ODEs) | Numerical Analysis B" />
  
  <meta name="twitter:description" content="These are the course notes for the numerical methods honours course taught to applied mathematics students at University of Johannesburg" />
  

<meta name="author" content="Byron Jacobs" />


<meta name="date" content="2021-07-27" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="taylor-series-revisted.html"/>
<link rel="next" href="partial-differential-equations.html"/>
<script src="libs/header-attrs-2.8/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">APM8X13</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prerequisites</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#course-outline"><i class="fa fa-check"></i><b>1.1</b> Course Outline</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#learning-outcomes"><i class="fa fa-check"></i><b>1.2</b> Learning outcomes</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#module-descriptor"><i class="fa fa-check"></i><b>1.3</b> Module Descriptor</a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#lectureconsultation-schedule"><i class="fa fa-check"></i><b>1.4</b> Lecture/Consultation Schedule</a></li>
<li class="chapter" data-level="1.5" data-path="intro.html"><a href="intro.html#lecturer-contact-details"><i class="fa fa-check"></i><b>1.5</b> Lecturer Contact Details</a></li>
<li class="chapter" data-level="1.6" data-path="intro.html"><a href="intro.html#additional-resources"><i class="fa fa-check"></i><b>1.6</b> Additional Resources</a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="intro.html"><a href="intro.html#pythongoogle-colab"><i class="fa fa-check"></i><b>1.6.1</b> Python/Google Colab</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="intro.html"><a href="intro.html#assessments"><i class="fa fa-check"></i><b>1.7</b> Assessments</a>
<ul>
<li class="chapter" data-level="1.7.1" data-path="intro.html"><a href="intro.html#assessment-schedule"><i class="fa fa-check"></i><b>1.7.1</b> Assessment schedule</a></li>
<li class="chapter" data-level="1.7.2" data-path="intro.html"><a href="intro.html#pass-requirements-and-compilation-of-marks"><i class="fa fa-check"></i><b>1.7.2</b> Pass Requirements and Compilation of Marks</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="intro.html"><a href="intro.html#rules-and-procedure-for-absence-from-an-assessment"><i class="fa fa-check"></i><b>1.8</b> Rules and Procedure for Absence from an Assessment</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="taylor-series-revisted.html"><a href="taylor-series-revisted.html"><i class="fa fa-check"></i><b>2</b> Taylor Series (Revisted)</a>
<ul>
<li class="chapter" data-level="2.1" data-path="taylor-series-revisted.html"><a href="taylor-series-revisted.html#higher-order-and-more-accurate-approximations"><i class="fa fa-check"></i><b>2.1</b> Higher order and more accurate approximations</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="ordinary-differentiable-equations-odes.html"><a href="ordinary-differentiable-equations-odes.html"><i class="fa fa-check"></i><b>3</b> Ordinary Differentiable Equations (ODEs)</a>
<ul>
<li class="chapter" data-level="3.1" data-path="ordinary-differentiable-equations-odes.html"><a href="ordinary-differentiable-equations-odes.html#initial-value-problems"><i class="fa fa-check"></i><b>3.1</b> Initial Value Problems</a></li>
<li class="chapter" data-level="3.2" data-path="ordinary-differentiable-equations-odes.html"><a href="ordinary-differentiable-equations-odes.html#converting-an-nth-order-ode-to-a-system-of-first-order-odes"><i class="fa fa-check"></i><b>3.2</b> Converting an <span class="math inline">\(n^{th}\)</span> Order ODE to a System of First Order ODEs</a></li>
<li class="chapter" data-level="3.3" data-path="ordinary-differentiable-equations-odes.html"><a href="ordinary-differentiable-equations-odes.html#stability-of-odes"><i class="fa fa-check"></i><b>3.3</b> Stability of ODEs</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="ordinary-differentiable-equations-odes.html"><a href="ordinary-differentiable-equations-odes.html#unstable-ode"><i class="fa fa-check"></i><b>3.3.1</b> Unstable ODE</a></li>
<li class="chapter" data-level="3.3.2" data-path="ordinary-differentiable-equations-odes.html"><a href="ordinary-differentiable-equations-odes.html#stable-ode"><i class="fa fa-check"></i><b>3.3.2</b> Stable ODE</a></li>
<li class="chapter" data-level="3.3.3" data-path="ordinary-differentiable-equations-odes.html"><a href="ordinary-differentiable-equations-odes.html#neutrally-stable-ode"><i class="fa fa-check"></i><b>3.3.3</b> Neutrally Stable ODE</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="ordinary-differentiable-equations-odes.html"><a href="ordinary-differentiable-equations-odes.html#eulers-method"><i class="fa fa-check"></i><b>3.4</b> Euler’s Method</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="ordinary-differentiable-equations-odes.html"><a href="ordinary-differentiable-equations-odes.html#error-in-eulers-method"><i class="fa fa-check"></i><b>3.4.1</b> Error in Euler’s Method</a></li>
<li class="chapter" data-level="3.4.2" data-path="ordinary-differentiable-equations-odes.html"><a href="ordinary-differentiable-equations-odes.html#example"><i class="fa fa-check"></i><b>3.4.2</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="ordinary-differentiable-equations-odes.html"><a href="ordinary-differentiable-equations-odes.html#accuracy-and-stability"><i class="fa fa-check"></i><b>3.5</b> Accuracy and Stability</a></li>
<li class="chapter" data-level="3.6" data-path="ordinary-differentiable-equations-odes.html"><a href="ordinary-differentiable-equations-odes.html#implicit-euler"><i class="fa fa-check"></i><b>3.6</b> Implicit Euler</a></li>
<li class="chapter" data-level="3.7" data-path="ordinary-differentiable-equations-odes.html"><a href="ordinary-differentiable-equations-odes.html#modified-eulers-method"><i class="fa fa-check"></i><b>3.7</b> Modified Euler’s Method</a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="ordinary-differentiable-equations-odes.html"><a href="ordinary-differentiable-equations-odes.html#example-1"><i class="fa fa-check"></i><b>3.7.1</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="ordinary-differentiable-equations-odes.html"><a href="ordinary-differentiable-equations-odes.html#runge-kutta-methods"><i class="fa fa-check"></i><b>3.8</b> Runge-Kutta Methods</a>
<ul>
<li class="chapter" data-level="3.8.1" data-path="ordinary-differentiable-equations-odes.html"><a href="ordinary-differentiable-equations-odes.html#second-order-runge-kutta-method"><i class="fa fa-check"></i><b>3.8.1</b> Second Order Runge-Kutta Method</a></li>
<li class="chapter" data-level="3.8.2" data-path="ordinary-differentiable-equations-odes.html"><a href="ordinary-differentiable-equations-odes.html#fourth-order-runge-kutta-method"><i class="fa fa-check"></i><b>3.8.2</b> Fourth Order Runge-Kutta Method</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="ordinary-differentiable-equations-odes.html"><a href="ordinary-differentiable-equations-odes.html#multistep-methods"><i class="fa fa-check"></i><b>3.9</b> Multistep Methods</a>
<ul>
<li class="chapter" data-level="3.9.1" data-path="ordinary-differentiable-equations-odes.html"><a href="ordinary-differentiable-equations-odes.html#adam-bashforth-moultonmethod"><i class="fa fa-check"></i><b>3.9.1</b> Adam-Bashforth-MoultonMethod</a></li>
<li class="chapter" data-level="3.9.2" data-path="ordinary-differentiable-equations-odes.html"><a href="ordinary-differentiable-equations-odes.html#advantages-of-multistep-methods"><i class="fa fa-check"></i><b>3.9.2</b> Advantages of Multistep Methods</a></li>
</ul></li>
<li class="chapter" data-level="3.10" data-path="ordinary-differentiable-equations-odes.html"><a href="ordinary-differentiable-equations-odes.html#systems-of-first-order-odes"><i class="fa fa-check"></i><b>3.10</b> Systems of First Order ODEs</a>
<ul>
<li class="chapter" data-level="3.10.1" data-path="ordinary-differentiable-equations-odes.html"><a href="ordinary-differentiable-equations-odes.html#r-k-method-for-systems"><i class="fa fa-check"></i><b>3.10.1</b> R-K Method for Systems</a></li>
<li class="chapter" data-level="3.10.2" data-path="ordinary-differentiable-equations-odes.html"><a href="ordinary-differentiable-equations-odes.html#exercises"><i class="fa fa-check"></i><b>3.10.2</b> Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="partial-differential-equations.html"><a href="partial-differential-equations.html"><i class="fa fa-check"></i><b>4</b> Partial Differential Equations</a>
<ul>
<li class="chapter" data-level="4.1" data-path="partial-differential-equations.html"><a href="partial-differential-equations.html#classification-of-partial-differential-equations"><i class="fa fa-check"></i><b>4.1</b> Classification of Partial Differential Equations</a></li>
<li class="chapter" data-level="4.2" data-path="partial-differential-equations.html"><a href="partial-differential-equations.html#time-dependent-problems"><i class="fa fa-check"></i><b>4.2</b> Time-Dependent Problems</a></li>
<li class="chapter" data-level="4.3" data-path="partial-differential-equations.html"><a href="partial-differential-equations.html#fully-discrete-methods"><i class="fa fa-check"></i><b>4.3</b> Fully Discrete Methods</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="partial-differential-equations.html"><a href="partial-differential-equations.html#explicit-finite-difference-method"><i class="fa fa-check"></i><b>4.3.1</b> Explicit Finite Difference Method</a></li>
<li class="chapter" data-level="4.3.2" data-path="partial-differential-equations.html"><a href="partial-differential-equations.html#sec:BCs"><i class="fa fa-check"></i><b>4.3.2</b> Boundary Conditions</a></li>
<li class="chapter" data-level="4.3.3" data-path="partial-differential-equations.html"><a href="partial-differential-equations.html#sec:implicitFD"><i class="fa fa-check"></i><b>4.3.3</b> Implicit Finite Difference Method</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="partial-differential-equations.html"><a href="partial-differential-equations.html#consistency-stability-and-convergence"><i class="fa fa-check"></i><b>4.4</b> Consistency, Stability and Convergence</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="partial-differential-equations.html"><a href="partial-differential-equations.html#consistency"><i class="fa fa-check"></i><b>4.4.1</b> Consistency</a></li>
<li class="chapter" data-level="4.4.2" data-path="partial-differential-equations.html"><a href="partial-differential-equations.html#von-neumann-stability-analysis"><i class="fa fa-check"></i><b>4.4.2</b> von Neumann Stability Analysis</a></li>
<li class="chapter" data-level="4.4.3" data-path="partial-differential-equations.html"><a href="partial-differential-equations.html#lax-equivalence-theorem"><i class="fa fa-check"></i><b>4.4.3</b> Lax Equivalence Theorem</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://www.uj.ac.za/faculties/science/mam/Pages/Postgraduate-Studies.aspx" target="blank">University of Johannesburg</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Numerical Analysis B</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ordinary-differentiable-equations-odes" class="section level1" number="3">
<h1><span class="header-section-number">Chapter 3</span> Ordinary Differentiable Equations (ODEs)</h1>
<p>Ordinary differential equations govern a great number of many important physical processes and phenomena. Not all differential equations can be solved using analytic techniques. Consequently, numerical solutions have become an alternative method of solution, and these have become a very large area of study.</p>
<p>Importantly, we note the following:</p>
<ul>
<li>By itself <span class="math inline">\(y^\prime = f(t, y)\)</span> does not determine a unique solution.</li>
<li>This simply tells us the slope <span class="math inline">\(y^\prime(t)\)</span> of the solution function at each point, but not the actual value <span class="math inline">\(y(t)\)</span> at any point.</li>
<li>There are an infinite family of functions satisfying an ODE.</li>
<li>To single out a particular solution, a value <span class="math inline">\(y_0\)</span> of the solution function must be specified at some point <span class="math inline">\(t_0\)</span>. These are called initial value problems.</li>
</ul>
<div id="initial-value-problems" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Initial Value Problems</h2>
<p>The general first order equation can be written as:
<span class="math display" id="eq:de1">\[\begin{equation}
{dy\over dt}=f(t,y),\tag{3.1}
\end{equation}\]</span>
with <span class="math inline">\(f(t,y)\)</span> given. Together with this may be given an initial condition, say <span class="math inline">\(y(t_0)=y_0,\)</span> in which case <a href="ordinary-differentiable-equations-odes.html#eq:de1">(3.1)</a> and this condition form an initial value problem. Its general solution contains a single arbitrary constant of integration which can be determined from the given initial condition.</p>
</div>
<div id="converting-an-nth-order-ode-to-a-system-of-first-order-odes" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> Converting an <span class="math inline">\(n^{th}\)</span> Order ODE to a System of First Order ODEs</h2>
Consider the ODE
<span class="math display" id="eq:highOrder">\[\begin{equation}
    \frac{d^n x(t)}{dt^n}= f(x(t),t). \tag{3.2}
\end{equation}\]</span>
By introducing a set of new variables, we are able to write equation <a href="ordinary-differentiable-equations-odes.html#eq:highOrder">(3.2)</a> as a system of <span class="math inline">\(n\)</span> first order ODEs. We let
<span class="math display">\[\begin{align}
    x_0(t) &amp;= x(t), \\
    x_1(t) &amp;= x&#39;(t),\\
    &amp;\vdots \\
    x_{n-1}(t) &amp;= x^{(n-1)}(t).
\end{align}\]</span>
Using the above we can write our <span class="math inline">\(n\)</span>th order ODE as a system <span class="math inline">\(n\)</span> of first order ODEs,
<span class="math display">\[\begin{equation}
    \left(
    \begin{array}{c}
    x&#39;_0(t)\\ 
    x&#39;_1(t)\\ 
    \vdots\\ 
    x&#39;_{n-2}(t)\\
    x&#39;_{n-1}(t)
    \end{array} 
    \right) = \left(
    \begin{array}{ccccc}
    0 &amp; 1 &amp; 0 &amp; \ldots &amp; 0 \\ 
    0 &amp; 0 &amp; 1 &amp; 0 &amp; \ldots \\ 
      &amp;   &amp;   &amp; \ddots &amp;  \\ 
  0 &amp; 0 &amp; \ldots &amp; 0 &amp; 1\\
    0 &amp; 0 &amp; \ldots &amp; 0 &amp; 0
    \end{array}
    \right) 
    \left(
    \begin{array}{c}
    x_0(t)\\ 
    x_1(t)\\ 
    \vdots\\ 
    x_{n-2}(t)\\ 
    x_{n-1}(t)\\ 
    \end{array} 
    \right) + 
    \left(
    \begin{array}{c}
    0\\ 
    0\\ 
    \vdots\\ 
    0\\
    f(x_0(t),t)
    \end{array} 
    \right).
\end{equation}\]</span>

<div class="example">
<span id="exm:unnamed-chunk-16" class="example"><strong>Example 3.1  </strong></span>Consider the general second order initial value problem
<span class="math display">\[  
y^{\prime\prime}+a y^\prime+b y=0,\quad y(0)=\alpha_1,\ \ \ \ y^\prime(0)=\alpha_2
\]</span>
If we let <span class="math display">\[x_0 = y, \ \ \ \ x_1=y^\prime,\ \ \ \ x_2^\prime=y^{\prime\prime}\]</span>
then the original ODE can now be written as
<span class="math display">\[\begin{eqnarray}
 x_0^\prime &amp;=&amp; x_1, \ \ \ \ x_0(0)=\alpha_1\\
 x_1^\prime &amp;=&amp; -a x_1 - b x_0,\ \ \ \ x_1(0)=\alpha_2
\end{eqnarray}\]</span>
Once transformed into a system of first order ODEs the methods for systems of equations apply.
</div>
</div>
<div id="stability-of-odes" class="section level2" number="3.3">
<h2><span class="header-section-number">3.3</span> Stability of ODEs</h2>
<p>Should members of the solution family of an ODE move away from each other over time, then the equation is said to be <strong>unstable</strong>. If the family members move closer to one another with time then the equation is said to be <strong>stable</strong>. Finally, if the solution curves do not approach or diverge from one another with time, then the equation is said to be <strong>neutrally stable</strong>. So small perturbations to a solution of a stable equation will be damped out with time since the solution curves are converging. Conversely, an unstable equation would see the perturbation grow with time as the solution curves diverge.</p>
<p>To give physical meaning to the above, consider a 3D cone. If the cone is stood on its circular base, then applying a perturbation to the cone will see it return to its original position standing up, implying a stable position. If the cone was balanced on its tip, then a small perturbation would see the cone fall, there the position is unstable. Finally, consider the cone resting on its side, applying a perturbation will simply roll the cone to some new position and thus the position is neutrally stable.</p>
<div id="unstable-ode" class="section level3" number="3.3.1">
<h3><span class="header-section-number">3.3.1</span> Unstable ODE</h3>
<p>An example of an unstable ODE is <span class="math inline">\(y^\prime = y\)</span>. Its family of solutions are given by the curves <span class="math inline">\(y(t) = ce^t\)</span>. From the exponential growth of the solutions we can see that the solution curves move away from one another as time increases implying that the equations is unstable. We can see this is the plot below.</p>

<p><img src="APM8X13_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
</div>
<div id="stable-ode" class="section level3" number="3.3.2">
<h3><span class="header-section-number">3.3.2</span> Stable ODE</h3>
<p>Now consider the equation <span class="math inline">\(y^\prime = -y\)</span>. Here the family of solutions is given by <span class="math inline">\(y(t) = ce^{-t}\)</span>. Since we have exponential decay of the solutions we can see that the equation is stable as seen in Figure below.</p>

<p><img src="APM8X13_files/figure-html/unnamed-chunk-4-3.png" width="672" /></p>
</div>
<div id="neutrally-stable-ode" class="section level3" number="3.3.3">
<h3><span class="header-section-number">3.3.3</span> Neutrally Stable ODE</h3>
<p>Finally, consider the ODE <span class="math inline">\(y^\prime = a\)</span> for a given constant <span class="math inline">\(a\)</span>. Here the family of solutions is given by <span class="math inline">\(y(t) = at + c\)</span>, where <span class="math inline">\(c\)</span> again is any real constant. Thus, in the example plotted below where <span class="math inline">\(a = \frac{1}{2}\)</span> the solutions are parallel straight lines which neither converge or diverge. Therefore, the equation is neutrally stable.</p>

<p><img src="APM8X13_files/figure-html/unnamed-chunk-4-5.png" width="672" /></p>
</div>
</div>
<div id="eulers-method" class="section level2" number="3.4">
<h2><span class="header-section-number">3.4</span> Euler’s Method</h2>
<p>The simplest numerical technique for solving differential equations is Euler’s method. It involves choosing a suitable step size <span class="math inline">\(h\)</span> and an initial value <span class="math inline">\(y(t_0)=y_0\)</span>, which are then used to estimate
<span class="math inline">\(y(t_1),\;y(t_2),\ldots\)</span> by a sequence of values <span class="math inline">\(y_i,\; i=1,2,\ldots\)</span>. Here use the notation <span class="math inline">\(t_i=t_0+ih\)</span>.</p>
<p>A method of accomplishing this is suggested by the Taylor’s expansion
<span class="math display">\[ 
y(t+h)=y(t)+h y^\prime(t)+{1\over 2!} h^2 y^{\prime\prime}(t)+{1\over 3!} h^3 y^{\prime\prime\prime}(t)+\cdots
\]</span>
or, in terms of the notation introduced above:
<span class="math display" id="eq:taylor1">\[\begin{equation}
y_{i+1}=y_i+h y_i^\prime+{1\over 2!} h^2 y_i^{\prime\prime}+ {1\over 3!} h^3 y_i^{\prime\prime\prime}+\cdots \tag{3.3}
\end{equation}\]</span>
By the differential equation <a href="ordinary-differentiable-equations-odes.html#eq:taylor1">(3.3)</a>, we have:
<span class="math display">\[ 
y_i^\prime=f(t_i,y_i)
\]</span>
which when substituted in <a href="ordinary-differentiable-equations-odes.html#eq:taylor1">(3.3)</a> yields:
<span class="math display" id="eq:taylor2">\[\begin{equation}
y_{i+1}=y_i+h f(t_i,y_i)+{1\over 2!} h^2 f^{\prime}(t_i,y_i)+ {1\over 3!} h^3 f^{\prime\prime}(t_i,y_i)+\cdots \tag{3.4}
\end{equation}\]</span>
and so if we truncate the Taylor series <a href="ordinary-differentiable-equations-odes.html#eq:taylor2">(3.4)</a> after the term in <span class="math inline">\(h\)</span>, we have the approximate formula:
<span class="math display" id="eq:euler1">\[\begin{equation}
y_{i+1}=y_i+ h f(t_i,y_i)\tag{3.5}
\end{equation}\]</span>
This is a difference formula which can be evaluated step by step. This is the formula for <strong>Euler’s (or Euler-Cauchy)</strong> method. Thus given <span class="math inline">\((t_0,y_0)\)</span> we can calculate <span class="math inline">\((t_i,y_i)\)</span> for <span class="math inline">\(i=1,2,\cdots, n\)</span>. Since the new value <span class="math inline">\(y_{i+1}\)</span> can be calculated from known values of <span class="math inline">\(t_i\)</span> and <span class="math inline">\(y_i\)</span>, this method is said to be <strong>explicit</strong>.</p>
<div id="error-in-eulers-method" class="section level3" number="3.4.1">
<h3><span class="header-section-number">3.4.1</span> Error in Euler’s Method</h3>
<p>Each time we apply an equation such as<a href="ordinary-differentiable-equations-odes.html#eq:euler1">(3.5)</a> we introduce two types of errors:</p>
<ul>
<li>Local truncation error introduced by ignoring the terms in <span class="math inline">\(h^2,\;h^3, \cdots\)</span> in equation <a href="ordinary-differentiable-equations-odes.html#eq:taylor1">(3.3)</a>. For Euler’s method, this error is
<span class="math display">\[
E ={h^2\over 2!} y_i^{\prime\prime}(\xi),\ \ \ \xi\in [t_i,t_{i+1}],
\]</span>
i.e. <span class="math inline">\(\epsilon_E=\mathcal{O}(h^2)\)</span>. Thus the local truncation error per step is <span class="math inline">\(\mathcal{O}(h^2)\)</span>.</li>
<li>A further error introduced in <span class="math inline">\(y_{i+1}\)</span> because <span class="math inline">\(y_i\)</span> is itself in error. The size of this error will depend on the function <span class="math inline">\(f(t,y)\)</span> and the step size <span class="math inline">\(h\)</span>.</li>
</ul>
<p>The above errors are introduced at each step of the calculation.</p>
<hr />
</div>
<div id="example" class="section level3" number="3.4.2">
<h3><span class="header-section-number">3.4.2</span> Example</h3>
<p>Apply the Euler’s method to solve the simple equation:
<span class="math display">\[ 
{dy\over dt}=t+y, \ \ \ \ y(0)=1
\]</span>
(Exercise: Solve the equation analytically and show that the analytic solution is <span class="math inline">\(y=2 e^t-t-1\)</span>.)</p>
<p><strong>Solution:</strong></p>
<p>Here <span class="math inline">\(f(t_i,y_i)=t_i+y_i.\)</span> With <span class="math inline">\(h=0.1,\)</span> and <span class="math inline">\(y_0=1\)</span> we compute <span class="math inline">\(y_1\)</span> as:
<span class="math display">\[ 
y_1=y_0+hf(t_0,y_0)=1+0.1(0+1)=1.1 
\]</span>
The numerical results of approtimate solutions at subsequent points <span class="math inline">\(t_1=0.2, \ldots\)</span> can be computed in a similar way, rounded to 3 decimal, to obtain places.</p>
<table>
<thead>
<tr class="header">
<th align="left"><span class="math inline">\(t\)</span></th>
<th align="left"><span class="math inline">\(y\)</span></th>
<th align="left"><span class="math inline">\(y^\prime=f(t,y)\)</span></th>
<th align="left"><span class="math inline">\(y^\prime h\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">0</td>
<td align="left">1.000</td>
<td align="left">1.000</td>
<td align="left">0.100</td>
</tr>
<tr class="even">
<td align="left">0.1</td>
<td align="left">1.100</td>
<td align="left">1.200</td>
<td align="left">0.120</td>
</tr>
<tr class="odd">
<td align="left">0.2</td>
<td align="left">1.220</td>
<td align="left">1.420</td>
<td align="left">0.142</td>
</tr>
<tr class="even">
<td align="left">0.3</td>
<td align="left">1.362</td>
<td align="left">1.662</td>
<td align="left">0.166</td>
</tr>
<tr class="odd">
<td align="left">0.4</td>
<td align="left">1.528</td>
<td align="left">1.928</td>
<td align="left">0.193</td>
</tr>
</tbody>
</table>
<p>The analytical solution at <span class="math inline">\(t=0.4\)</span> is 1.584. The numerical value is 1.528 and hence the error is about <span class="math inline">\(3.5\%\)</span>. The accuracy of the Euler’s method can be improved by using a smaller step size <span class="math inline">\(h\)</span>. Another alternative is to use a more accurate algorithm.</p>

<p><img src="APM8X13_files/figure-html/unnamed-chunk-4-7.png" width="672" /></p>
</div>
</div>
<div id="accuracy-and-stability" class="section level2" number="3.5">
<h2><span class="header-section-number">3.5</span> Accuracy and Stability</h2>
<p>The accuracy of a numerical method is impacted upon by two sources of error:
* Rounding error, which is inherent in the floating point representation of real numbers on a computer
* Truncation error, which is due to the selected method and for our purposes associated with the truncation of the Taylor series.</p>
<p>Broadly speaking truncation error dominates the error in a numerical method, and as such, will be the focus of our analysis. For a given numerical approximation, <span class="math inline">\(y_i\)</span>, to the true solution, <span class="math inline">\(y_(t_i)\)</span>, at a point <span class="math inline">\(t_i\)</span> we can define the <em>global error</em>
<span class="math display">\[
  e_i = y_i - y(t_i).
\]</span>
We may also define the <em>local error</em> as the truncation error incurred moving from an approximation at <span class="math inline">\(t_{k-1}\)</span> to <span class="math inline">\(t_k\)</span>. Since these local errors compound and affect the solution as time evolves, it is more meaningful to assess the global error of a method as a performance measure of a given numerical method.</p>
<p>A given numerical method is said to be <span class="math inline">\(p\)</span>th order accurate if the global error acts like <span class="math inline">\(\mathcal{O}(h^p)\)</span>.</p>
<p>Another important aspect of a numerical method is <em>stability</em>. In an analgous manner to the stability of ODEs, a numerical method is <em>stable</em> if small perturbations do not generate divergence of the numerical solution from the exact solution.</p>

<div class="example">
<span id="exm:unnamed-chunk-21" class="example"><strong>Example 3.2  </strong></span>Considering,
<span class="math display">\[ 
  y&#39;(t) = \lambda y(t), \ \ \ \ y(0) = y_0.
\]</span>
Where <span class="math inline">\(\lambda\)</span> is potential complex valued and the exact solution of which is given by <span class="math inline">\(y(t) = y_0 e^{\lambda t}\)</span>.
Applying Euler’s method to this equation gives
<span class="math display">\[
  y_{i+1} = (1+h \lambda) y_i,
\]</span>
which implies
<span class="math display">\[
  y_i = (1+h\lambda)^i y_0.
\]</span>
We refer to <span class="math inline">\((1+h\lambda)\)</span> as the growth factor. If <span class="math inline">\(\Re(\lambda) &lt; 0\)</span> then the exact solution exhibits decaying behaviour. Similarly the Euler approximation will decay if <span class="math inline">\((1+h\lambda) &lt; 1\)</span>, if <span class="math inline">\((1+h\lambda) &gt;1\)</span> then the approximation will diverge and the method is unstable.
</div>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="ordinary-differentiable-equations-odes.html#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb4-2"><a href="ordinary-differentiable-equations-odes.html#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb4-3"><a href="ordinary-differentiable-equations-odes.html#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> eulerEx1(dt, T<span class="op">=</span><span class="dv">1</span>, y0 <span class="op">=</span> <span class="dv">1</span>):</span>
<span id="cb4-4"><a href="ordinary-differentiable-equations-odes.html#cb4-4" aria-hidden="true" tabindex="-1"></a>  ys<span class="op">=</span>[y0]</span>
<span id="cb4-5"><a href="ordinary-differentiable-equations-odes.html#cb4-5" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> i <span class="kw">in</span> np.arange(<span class="bu">int</span>(np.ceil(T<span class="op">/</span>dt))):</span>
<span id="cb4-6"><a href="ordinary-differentiable-equations-odes.html#cb4-6" aria-hidden="true" tabindex="-1"></a>    ys <span class="op">=</span> ys <span class="op">+</span> [ys[<span class="op">-</span><span class="dv">1</span>]<span class="op">-</span>dt<span class="op">*</span>ys[<span class="op">-</span><span class="dv">1</span>]]</span>
<span id="cb4-7"><a href="ordinary-differentiable-equations-odes.html#cb4-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-8"><a href="ordinary-differentiable-equations-odes.html#cb4-8" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> [np.arange(<span class="bu">int</span>(np.ceil(T<span class="op">/</span>dt))<span class="op">+</span><span class="dv">1</span>)<span class="op">*</span>dt, ys]</span></code></pre></div>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="ordinary-differentiable-equations-odes.html#cb5-1" aria-hidden="true" tabindex="-1"></a>[xs, ys] <span class="op">=</span> eulerEx1(<span class="fl">0.5</span>,<span class="dv">200</span>)</span></code></pre></div>

<p><img src="APM8X13_files/figure-html/unnamed-chunk-4-9.png" width="672" /></p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="ordinary-differentiable-equations-odes.html#cb6-1" aria-hidden="true" tabindex="-1"></a>[xs, ys] <span class="op">=</span> eulerEx1(<span class="fl">1.9</span>,<span class="dv">200</span>)</span></code></pre></div>

<p><img src="APM8X13_files/figure-html/unnamed-chunk-4-11.png" width="672" /></p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="ordinary-differentiable-equations-odes.html#cb7-1" aria-hidden="true" tabindex="-1"></a>[xs, ys] <span class="op">=</span> eulerEx1(<span class="fl">2.1</span>,<span class="dv">200</span>)</span></code></pre></div>

<p><img src="APM8X13_files/figure-html/unnamed-chunk-4-13.png" width="672" /></p>
<p>The above plots illustrate the importance of step size, <span class="math inline">\(h\)</span>, on both accuracy and stability. By looking at the truncation error in the Euler method we have that
<span class="math display">\[
  \frac{h^2}{2!} \|y&#39;&#39;(c)\| \le tol,
\]</span>
where <span class="math inline">\(tol\)</span> is the specified error tolerance, and <span class="math inline">\(c\)</span> is some value in the domain of approximation. This leads to
<span class="math display">\[
h \le \sqrt{\frac{2 tol}{\|y&#39;&#39;(c)\|}}.
\]</span>
In this equation, <span class="math inline">\(\|y&#39;&#39;(c)\|\)</span> can’t be known, since <span class="math inline">\(y(t)\)</span> is the thing we’re trying to find. So the curvature can be approximated by
<span class="math display">\[
\|y&#39;&#39;(t_i)\| \approx \frac{y&#39;_i - y&#39;_{i-1}}{t_i-t_{i-1}},
\]</span>
for example.</p>
</div>
<div id="implicit-euler" class="section level2" number="3.6">
<h2><span class="header-section-number">3.6</span> Implicit Euler</h2>
<p>Euler’s method above is an example of an <em>explicit</em> method. Explicit methods only rely on known information in the update schema. The advantage of this is that these methods are often easy to implement, they are broadly applicable (linear/nonlinear equations), however they can exhibit accuracy and stability issues as has been shown above.</p>
<p>Implicit methods require information at the current <em>unknown</em> time step to iterate. The backward Euler method is an example of an implicit method, given by
<span class="math display">\[
  y_{i+1} = y_i + h f(t_{i+1},y_{i+1}).
\]</span>
The method is clearly implicit due to the requirement of <span class="math inline">\(y_{i+1}\)</span>, the currently <strong>unknown</strong> time step, in the function evaluation.
### Stability of the Implicit Approach
Considering again the test equation
<span class="math display">\[
  y&#39; = \lambda y, \ \ \ \ y(0) = y_0,
\]</span>
we may approximate the solution using the implicit method, yielding
<span class="math display">\[
  y_{i+1} = y_{i} + h \lambda y_{i+1}.
\]</span>
Rearranging we find
<span class="math display">\[
  y_{i+1} = \left(\frac{1}{1-h\lambda}\right)^i y_0.
\]</span>
The stability condition on the growth factor suggests that
<span class="math display">\[
\left|\frac{1}{1-h\lambda}\right| \le 1,
\]</span>
which holds <span class="math inline">\(\forall h &gt; 0\)</span>, when <span class="math inline">\(\Re(\lambda) &lt; 0\)</span>.</p>
</div>
<div id="modified-eulers-method" class="section level2" number="3.7">
<h2><span class="header-section-number">3.7</span> Modified Euler’s Method</h2>
<p>A fundamental source of error in Euler’s method is that the derivative at the beginning of the interval is assumed to apply across the entire subinterval.</p>
<p>There are two ways we can modify the Euler method to produce better results. One method is due to Heun (<strong>Heun’s method</strong>) and is well documented in numerical text books. The other method we consider here is called the <strong>improved polygon</strong> (or <strong>modified Euler</strong>) method.</p>
<p>The modified Euler technique uses Euler’s method to predict the value of <span class="math inline">\(y\)</span> at the midpoint of the interval <span class="math inline">\([t_i,t_{i+1}]\)</span>:
<span class="math display">\[\begin{equation}
y_{i+\frac{1}{2}}=y_i+f(t_i,y_i) {h\over 2}.
\end{equation}\]</span>
Then this predicted value is used to estimate a slope at the midpoint:
<span class="math display">\[\begin{equation}
y_{i+\frac{1}{2}}^\prime=f(t_{i+1/2},y_{i+1/2}),
\end{equation}\]</span>
which is assumed to represent a valid approximation of the average slope for the entire subinterval. This slope is then used to extrapolate linearly from <span class="math inline">\(t_i\)</span> to <span class="math inline">\(x_{i+1}\)</span> using Euler’s method to obtain:
<span class="math display">\[\begin{equation}
y_{i+1}=y_i+ f(t_{i+1/2},y_{i+1/2}) h
\end{equation}\]</span>
For the modified Euler method, the truncation error can be shown to be:
<span class="math display">\[\begin{equation}
\epsilon_E =-{h^3\over 12} y_i^{\prime\prime\prime}(\xi),\ \ \ \ \xi\in [t_i,t_{i+1}] 
\end{equation}\]</span>
<strong>Note</strong>: <span class="math inline">\(t_{i + \frac{1}{2}} = t_i + \frac{1}{2}\)</span></p>
<div id="example-1" class="section level3" number="3.7.1">
<h3><span class="header-section-number">3.7.1</span> Example</h3>
<p>Solve
<span class="math display">\[ 
{dy\over dt}=t+y,\ \ \ \  y(0)=1, \ \ \ \ h=0.1
\]</span>
using the modified Euler’s method described above.</p>
<p><strong>Solution:</strong></p>
<table>
<thead>
<tr class="header">
<th align="left"><span class="math inline">\(t_i\)</span></th>
<th align="left"><span class="math inline">\(y_i\)</span></th>
<th align="left"><span class="math inline">\(y_{i+1/2}\)</span></th>
<th align="left"><span class="math inline">\(y_{i+1/2}^\prime\)</span></th>
<th align="left"><span class="math inline">\(y_{i+1/2}^\prime h\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">0</td>
<td align="left">1.000</td>
<td align="left">1.050</td>
<td align="left">1.100</td>
<td align="left">0.110</td>
</tr>
<tr class="even">
<td align="left">0.1</td>
<td align="left">1.110</td>
<td align="left">1.1705</td>
<td align="left">1.3205</td>
<td align="left">0.13205</td>
</tr>
<tr class="odd">
<td align="left">0.2</td>
<td align="left">1.24205</td>
<td align="left">1.1705</td>
<td align="left">1.3205</td>
<td align="left">0.13205</td>
</tr>
<tr class="even">
<td align="left">0.3</td>
<td align="left">1.39847</td>
<td align="left">1.31415</td>
<td align="left">1.56415</td>
<td align="left">0.15641</td>
</tr>
<tr class="odd">
<td align="left">0.4</td>
<td align="left">1.58180</td>
<td align="left">1.48339</td>
<td align="left">1.83339</td>
<td align="left">0.18334</td>
</tr>
</tbody>
</table>
<p>The numerical solution is now 1.5818 which much more accurate that the result obtained using Euler’s method. In this case the error is about <span class="math inline">\(0.14\%\)</span>.</p>

<p><img src="APM8X13_files/figure-html/unnamed-chunk-4-15.png" width="672" /></p>
</div>
</div>
<div id="runge-kutta-methods" class="section level2" number="3.8">
<h2><span class="header-section-number">3.8</span> Runge-Kutta Methods</h2>
<p>Runge and Kutta were German mathematicians. They suggested a group of methods for numerical solutions of ODEs.</p>
<p>The general form of the Runge-Kutta method is:
<span class="math display">\[\begin{equation} 
y_{i+1}=y_i+h\phi(t_i,y_i;h),
\end{equation}\]</span>
where <span class="math inline">\(\phi(t_i,y_i;h)\)</span> is called the increment function.</p>
<p>In Euler’s method, <span class="math inline">\(\phi(t_i,y_i;h)=f(t_i,y_i)=y_i^\prime\)</span>, i.e we are using the slope at the point <span class="math inline">\(t_i\)</span> to extrapolate <span class="math inline">\(y_i\)</span> and obtain <span class="math inline">\(y_{i+1}\)</span>. In the modified Euler’s method:
<span class="math display">\[
\phi(t_i,y_i;h)=f(t_{i+\frac{1}{2}},y_{i+\frac{1}{2}})=y_{i+\frac{1}{2}}^\prime
\]</span>
The increment function can be written in a general form as:
<span class="math display">\[\begin{equation}
\phi= w_1 k_1+w_2 k_2+\cdots+w_n k_n
\end{equation}\]</span>
where the <span class="math inline">\(k\)</span>’s are constants and the <span class="math inline">\(w\)</span>’s are weights.</p>
<div id="second-order-runge-kutta-method" class="section level3" number="3.8.1">
<h3><span class="header-section-number">3.8.1</span> Second Order Runge-Kutta Method</h3>
<p>The second order R-K method has the form:
<span class="math display" id="eq:runge2">\[\begin{equation}
y_{i+1}=y_i+(w_1 k_1+ w_2 k_2), \tag{3.6}
\end{equation}\]</span>
where
<span class="math display">\[\begin{eqnarray}
k_1 &amp;=&amp; h f(t_i,y_i)\\
k_2 &amp;=&amp;hf(t_i+{h\over 2} ,y_i+{k_1\over 2} ),
\end{eqnarray}\]</span>
and the weights <span class="math inline">\(w_1+w_2=1\)</span>. If <span class="math inline">\(w_1=1\)</span>, then <span class="math inline">\(w_2=0\)</span> and we have Euler’s method. If <span class="math inline">\(w_2=1\)</span>, then <span class="math inline">\(w_1=0\)</span> we have the Euler’s improved polygon method:
<span class="math display">\[\begin{eqnarray}
y_{i+1} &amp;=&amp; y_i+ k_2 \\
 &amp;=&amp;  y_i+ h f(t_i+{h\over 2} ,y_i+{k_1\over 2} ),
\end{eqnarray}\]</span>
If <span class="math inline">\(w_1=w_2=\frac{1}{2}\)</span>, then we have:
<span class="math display">\[\begin{eqnarray}
y_{i+1}&amp;=&amp; y_i+{1\over 2}(k_1+k_2),\\
k_1 &amp;=&amp; h f(t_i,y_i)\\
k_2 &amp;=&amp;hf(t_i+{h\over 2} ,y_i+{k_1\over 2} ),
\end{eqnarray}\]</span>
called Heun’s method.</p>
</div>
<div id="fourth-order-runge-kutta-method" class="section level3" number="3.8.2">
<h3><span class="header-section-number">3.8.2</span> Fourth Order Runge-Kutta Method</h3>
<p>The <strong>classical fourth order R–K method</strong> has the form:
<span class="math display" id="eq:runge4">\[\begin{equation}
y_{i+1}=y_i+{1\over 6}(k_1+2 k_2+2 k_3+k_4), \tag{3.7}
\end{equation}\]</span>
where
<span class="math display">\[\begin{eqnarray}
k_1 &amp;=&amp; hf(t_i,y_i)\\
k_2 &amp;=&amp; hf(t_i+{h\over 2} ,y_i+{k_1\over 2} )\\
k_3 &amp;=&amp; hf(t_i+{h\over 2} ,y_i+{k_2\over 2})\\
k_4 &amp;=&amp; hf(t_i+h ,y_i+k_3),
\end{eqnarray}\]</span>
This is the most popular R–K method. It has a local truncation error <span class="math inline">\(\mathcal{O}(h^4)\)</span></p>
<div id="example-2" class="section level4" number="3.8.2.1">
<h4><span class="header-section-number">3.8.2.1</span> Example</h4>
<p>Solve the DE <span class="math inline">\(y^\prime=t+y\)</span>, <span class="math inline">\(y(0)=1\)</span> using <span class="math inline">\(4^{th}\)</span> order Runge–Kutta method. Compare your results with those obtained from Euler’s method, modified Euler’s method and the actual value. Determine <span class="math inline">\(y(0.1)\)</span> and <span class="math inline">\(y(0.2)\)</span> only.</p>
<p>The solution using Runge-Kutta is obtained as follows:</p>
<p>For <span class="math inline">\(y_1:\)</span>
<span class="math display">\[\begin{eqnarray}
k_1&amp;=&amp;0.1(0+1)=0.1\\
k_2&amp;=&amp;0.1\left(\left(0+\frac{0.1}{2}\right)+\left(1+\frac{0.1}{2}\right)\right)=0.01\\
k_3&amp;=&amp;0.1\left(\left(0+\frac{0.1}{2}\right)+\left(1+\frac{0.11}{2}\right)\right)=0.1105\\
k_4&amp;=&amp;0.1(\left(0+0.1\right)+\left(1+0.1105\right))=0.1211
\end{eqnarray}\]</span>
and therefore:
<span class="math display">\[
y_1=y_0+\frac{1}{6}(0.1+2(0.01)+2(0.1105)+0.1211)=1.1103
\]</span>
A similar computation yields
<span class="math display">\[ 
y(0.2)=y_2=1.1103+\frac{1}{6}(0.1210+2(0.1321)+2(0.1326)+0.1443=1.2428 
\]</span>
A table for all the approximate solutions using the required methods is:</p>
<table>
<thead>
<tr class="header">
<th align="left"><span class="math inline">\(t\)</span></th>
<th align="left">Euler</th>
<th align="left">Modified Euler</th>
<th align="left"><span class="math inline">\(4^{th}\)</span> Order RK</th>
<th align="left">Actual value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">0.1</td>
<td align="left">1.1000000</td>
<td align="left">1.1100000</td>
<td align="left">1.1103417</td>
<td align="left">1.1103418</td>
</tr>
<tr class="even">
<td align="left">0.2</td>
<td align="left">1.2300000</td>
<td align="left">1.2420500</td>
<td align="left">1.2428052</td>
<td align="left">1.2428055</td>
</tr>
</tbody>
</table>

<p><img src="APM8X13_files/figure-html/unnamed-chunk-4-17.png" width="672" /></p>
</div>
</div>
</div>
<div id="multistep-methods" class="section level2" number="3.9">
<h2><span class="header-section-number">3.9</span> Multistep Methods</h2>
<p>As previously, Euler’s method, Modified Euler’s method and Runge-Kutta methods are single-step methods. They work by computing each successive value <span class="math inline">\(y_{i + 1}\)</span> only utilising information from the preceding value <span class="math inline">\(y_n\)</span>. Another approach are <em>multistep methods</em>, where values from several computed previously computed steps are used to obtain <span class="math inline">\(y_{i+1}\)</span>. There are numerous methods using this approach, however, for the purpose of this course we will only consider one - the <strong>Adam Bashforth Method</strong>.</p>
<div id="adam-bashforth-moultonmethod" class="section level3" number="3.9.1">
<h3><span class="header-section-number">3.9.1</span> Adam-Bashforth-MoultonMethod</h3>
<p>This is a multistep method is similar to the Modified Euler’s method in that it is a predictor-corrector method, i.e. uses one formula to predict a value <span class="math inline">\(y^\prime_{i + 1}\)</span>, which is then used to obtain a corrected value <span class="math inline">\(y_{i+ 1}\)</span>. The predictor in this method is the Adams-Bashforth formula. Specifically,
<span class="math display">\[\begin{eqnarray*}
y^*_{i + 1} &amp;=&amp; y_i + \dfrac{h}{24}(55y^\prime_i - 59y^\prime_{i-1} +37y^\prime_{i-2} - 9y^\prime_{i-3}),\\
y^\prime_i &amp;=&amp; f(t_i, y_i), \\
y^\prime_{i-1} &amp;=&amp; f(t_{i-1}, y_{i - 1}),\\
y^\prime_{i-2} &amp;=&amp; f(t_{i-2}, y_{i - 2}),\\
y^\prime_{i-3} &amp;=&amp; f(t_{i-3}, y_{i - 3}),
\end{eqnarray*}\]</span>
for <span class="math inline">\(i \geq 3\)</span>, which is then substituted into the Adams-Moulton corrector:
<span class="math display" id="eq:adam">\[\begin{eqnarray}
y_{i + 1} &amp;=&amp; y_i + \dfrac{h}{24}(9y^\prime_{i + 1} + 19^\prime_{i} - 5y^\prime_{i-1} + y^\prime_{i-2}) \tag{3.8} \\
y_{i + 1}^\prime &amp;=&amp; f(t_{i + 1}, y^*_{i+ 1}).
\end{eqnarray}\]</span>
Note that Equation <a href="ordinary-differentiable-equations-odes.html#eq:adam">(3.8)</a> requires that we know the initial values of <span class="math inline">\(y_0, y_1, y_2\)</span> and <span class="math inline">\(y_3\)</span> in order to obtain <span class="math inline">\(y_4\)</span>. The value <span class="math inline">\(y_0\)</span> is the initial condition. Since Adams-Bashforth method is of <span class="math inline">\(\mathcal{O}(h^5)\)</span>, we need a high order accurate method to first obtain <span class="math inline">\(y_1, y_2\)</span> and <span class="math inline">\(y_3\)</span>. Therefore, we compute these values using the RK-4 formula.</p>
<hr />
<div id="example-3" class="section level4" number="3.9.1.1">
<h4><span class="header-section-number">3.9.1.1</span> Example</h4>
<p>Use the Adam-Bashforth method with <span class="math inline">\(h = 0.2\)</span> to obtain an approximation to <span class="math inline">\(y(0.8)\)</span> for the IVP:
<span class="math display">\[
y^\prime = t + y - 1, \ \ \ \ y(0) = 1.
\]</span>
<strong>Solution:</strong></p>
<p>Using the RK-4 method to get started, we obtain the following:
<span class="math display">\[
y_1 = 1.0214, \ \ \ y_2 = 1.09181796, \ \ \ y_3 = 1.22210646.
\]</span>
Since <span class="math inline">\(h = 0.2\)</span>, we know that <span class="math inline">\(t_1 = 0.2, t_2 = 0.4, t_3 = 0.6\)</span> and <span class="math inline">\(f(t, y) = t + y - 1\)</span>. Now we can proceed:
<span class="math display">\[\begin{eqnarray*}
y^\prime_{0} &amp;=&amp; f(t_0, y_0) = 0 + 1 -1 = 0,\\
y^\prime_1   &amp;=&amp; f(t_1, y_1) = 0.2 + 1.0214 - 1 = 0.2214, \\
y^\prime_{2} &amp;=&amp; f(t_2, y_2) = 0.4 + 1.09181796 - 1 = 0.49181796,\\
y^\prime_{3} &amp;=&amp; f(t_3, y_3) = 0.6 + 1.22210646 - 1 = 0.82210646.\\
\end{eqnarray*}\]</span>
Now we can compute the predictor <span class="math inline">\(y^*_4\)</span>:
<span class="math display">\[
y^\prime_4 = y_3 + \dfrac{0.2}{24}(55y^\prime_3 - 59y^\prime_{2} +37y^\prime_{1} - 9y^\prime_{0}) = 1.42535975.
\]</span>
Next, we need <span class="math inline">\(y^\prime_4\)</span>:
<span class="math display">\[
y^\prime_4 = f(t_4, y^*_4) = 0.8 +1.42535975 - 1 = 1.22535975.
\]</span>
Finally, this gives <span class="math inline">\(y_4\)</span> by:
<span class="math display">\[
y_4 = y_3 + \dfrac{0.2}{24}(9y^\prime_4 + 19^\prime_{3} - 5y^\prime_{2} + y^\prime_{1}) = 1.42552788.
\]</span>
The exact solution of this ODE at <span class="math inline">\(y(0.8)\)</span> is 1.42554093.</p>
<hr />
</div>
</div>
<div id="advantages-of-multistep-methods" class="section level3" number="3.9.2">
<h3><span class="header-section-number">3.9.2</span> Advantages of Multistep Methods</h3>
<p>There are a number of decisions to make when choosing a numerical method to solve a differential equation. While single step explicit methods such as RK-4 are often chosen due to their accuracy and easily programmable implementation, the right hand side of the equation needs to be evaluated many times. In the case of RK-4, the method is required to make four function evaluations at each step. On the Implicit side, if the function valuations in the previous step have been computed and stored, then a multistep method would require only one new function evaluation at each step - saving computational time.</p>
<p>In general the Adam-Bashforth method requires slightly more than one quarter of the number of function evaluations required for the RK-4 method.</p>
<hr />
</div>
</div>
<div id="systems-of-first-order-odes" class="section level2" number="3.10">
<h2><span class="header-section-number">3.10</span> Systems of First Order ODEs</h2>
<p>A <span class="math inline">\(n\)</span>th order system of first order initial value problems can be expressed in the form:</p>
<p><span class="math display">\[\begin{eqnarray*}
{d y_1\over dt} &amp;=&amp; f_1(t, y_1,y_2,\cdots, y_n),\ \ \ \ y_1(t_0)=\alpha_1\\
{d y_2\over dt} &amp;=&amp; f_2(t, y_1,y_2,\cdots, y_n),\ \ \ \ y_2(t_0)=\alpha_2\\
\vdots\\
{d y_n\over dt} &amp;=&amp; f_n(t, y_1,y_2,\cdots, y_n),\ \ \ \ y_n(t_0)=\alpha_n,
\end{eqnarray*}\]</span>
for <span class="math inline">\(t_0\leq t\leq t_n\)</span>.</p>
<p>The methods we have seen so far were for a single first order equation, in which we sought the solution <span class="math inline">\(y(t)\)</span>. Methods to solve first order systems of IVP are simple generalization of
methods for a single equations, bearing in mind that now we seek <span class="math inline">\(n\)</span> solutions <span class="math inline">\(y_1,\; y_2,\ldots,y_n\)</span> each with an intial condition <span class="math inline">\(y_k(t_0); k=1,\ldots,n\)</span> at the points <span class="math inline">\(t_i,\; i=1,2.\ldots\)</span>.</p>
<div id="r-k-method-for-systems" class="section level3" number="3.10.1">
<h3><span class="header-section-number">3.10.1</span> R-K Method for Systems</h3>
<p>Consider the system of two equations:</p>
<p><span class="math display">\[\begin{eqnarray}
{d y\over dt} &amp;=&amp;f(t, y,z),\quad y(0)=y_0\\
{d z\over dt} &amp;=&amp;g(t, y,z),\quad z(0)=z_0.
\end{eqnarray}\]</span>
Let <span class="math inline">\(y=y_1,\; z=y_2,\; f=f_1,\;\)</span> and <span class="math inline">\(g=f_2.\)</span> The fourth order R-K method would be applied as follows. For each <span class="math inline">\(j=1,2\)</span> corresponding to solutions <span class="math inline">\(y_{j,i},\)</span> compute
<span class="math display">\[\begin{eqnarray}
k_{1,j}&amp;=&amp; hf_j(t_i,y_{1,i},y_{2,i}),\ \ j=1,2\\
k_{2,j}&amp;=&amp; hf_j(t_i+\frac{h}{2},\;y_{1,i}+\frac{k_{1,1}}{2},\;y_{2,i}+\frac{k_{1,2}}{2})\ \ j=1,2\\
k_{3,j}&amp;=&amp; hf_j(t_i+\frac{h}{2},\;y_{1,i}+\frac{k_{2,1}}{2},\;y_{2,i}+\frac{k_{2,2}}{2}), \ \ j=1,2\\
k_{4,j}&amp;=&amp; hf_j(t_i+h,\;y_{1,i}+k_{3,1},\;y_{2,i}+k_{3,2}),\ \ j=1,2
\end{eqnarray}\]</span>
and:
<span class="math display">\[\begin{eqnarray}
y_{i+1}=y_{1,i+1} &amp;=&amp; y_{1,i}+{1\over 6}(k_{1,1}+2k_{2,1}+2 k_{3,1}+ k_{4,1})\\
z_{i+1}=y_{2,i+1} &amp;=&amp; z_i+{1\over 6}(k_{1,2}+2k_{2,2}+2k_{3,2}+ k_{4,2}).
\end{eqnarray}\]</span>
Note that we must calculate <span class="math inline">\(k_{1,1},\; k_{1,2},\; k_{2,1},\;k_{2,2},\;k_{3,1},\;k_{3,2},\; k_{4,1},\; k_{4,2}\)</span> in that order.</p>
<div id="exercise" class="section level4" number="3.10.1.1">
<h4><span class="header-section-number">3.10.1.1</span> Exercise</h4>
<p>Solve the second order differential equation:
<span class="math display">\[
y^{\prime\prime}+3 ty^\prime +2 t^2 y=0,\ \ \ \ y(0)=3,\ \ \ \ y^\prime(0)=1
\]</span>
(i) Second order R–K method (ii) 4th order R–K.
Use <span class="math inline">\(h=0.1\)</span>. Do only two steps.</p>
<hr />
</div>
</div>
<div id="exercises" class="section level3" number="3.10.2">
<h3><span class="header-section-number">3.10.2</span> Exercises</h3>
<p>Use (i) Euler’s method (ii) modified Euler’s formula to solve the following IVP;</p>
<ul>
<li><span class="math inline">\(y^\prime=\sin(t+y),\ \ \ y(0)=0\)</span></li>
<li><span class="math inline">\(y^\prime=y t^2-y,\ \ \ \ y(0)=1\)</span>
for <span class="math inline">\(h=0.2\)</span> and <span class="math inline">\(h=0.1\)</span>.</li>
<li>Determine <span class="math inline">\(y(0.4)\)</span> for each of the above IVP.
<!-- * Use Richardson's extrapolation to get improved approximations to the solutions at $t=0.4$ --></li>
<li>Solve the second order differential equation:
<span class="math display">\[
y^{\prime\prime}+3 ty^\prime +2 t^2 y=0,\ \ \ \ y(0)=3,\ \ \ \ y^\prime(0)=1
\]</span></li>
</ul>
<ol style="list-style-type: lower-roman">
<li>Second order R–K method (ii) 4th order R–K.
Use <span class="math inline">\(h=0.1\)</span>. Do only two steps.</li>
</ol>
<ul>
<li>If <span class="math inline">\(f\)</span> is a function of <span class="math inline">\(t\)</span> only, show that the fourth-order Runge-Kutta formula, applied to the differential equation <span class="math inline">\(\displaystyle dy/dt=f(t)\)</span> is equivalent to the use of Simpson’s rule (over one interval) for evaluating <span class="math inline">\(\int_{0}^t f(t) dt\)</span>.</li>
<li>Use fourth order Runge–Kutta method to solve the following IVPs:
<ul>
<li><span class="math inline">\(y^\prime = 2 t y,\ \ \ \ y(0)=1\)</span><br />
</li>
<li><span class="math inline">\(y^\prime =1+y^2, \ \ \ \ y(0)=0\)</span>,
Use <span class="math inline">\(h=0.2\)</span> and determine the solutions at <span class="math inline">\(t=0.4\)</span>.</li>
</ul></li>
<li>Solve the following systems of IVPs:
<ul>
<li><span class="math inline">\(y^\prime=y z,\ \ \ \ z^\prime=t z,\ \ \ \ y(0)=1,\ \ \ \ z(0)=-1\)</span></li>
<li><span class="math inline">\(y^\prime=t-z^2,\ \ \ \ z^\prime=t+y,\ \ \ \ y(0)=1\ \ \ \ z(0)=2\)</span>,
using (i) Euler’s method (ii) Second order Runge-Kutta with <span class="math inline">\(h=0.1\)</span>. Compute <span class="math inline">\(y\)</span> and <span class="math inline">\(z\)</span>, at <span class="math inline">\(t=0.2\)</span>.</li>
</ul></li>
<li>Use Euler’s method to solve the differential equation:
<span class="math display">\[
y^\prime = 1 + y^2,
\]</span>
on the domain <span class="math inline">\([0,\ 1]\)</span> with the initial condition of (a) <span class="math inline">\(y_0 = 0\)</span> and (b) <span class="math inline">\(y_0 = 1\)</span>. Plot these solutions along with the exact solution. Use step sizes of <span class="math inline">\(h = 0.1\)</span> and <span class="math inline">\(h = 0.05\)</span>.</li>
<li>Given the IVP <span class="math inline">\(y^\prime = (t + y - 1)^2\)</span>, <span class="math inline">\(y(0) = 2\)</span>. Using the Modified Euler’s method with <span class="math inline">\(h = 1\)</span> and <span class="math inline">\(h = 0.05\)</span>, obtain approximate solutions of the solution at <span class="math inline">\(t = 0.5\)</span>. Compare these values with the analytical solution.</li>
</ul>
<hr />

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="taylor-series-revisted.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="partial-differential-equations.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["APM8X13.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
